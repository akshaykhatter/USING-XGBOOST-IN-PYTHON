# USING-XGBOOST-IN-PYTHON

## Features:

## Speed and performance :
Originally written in C++, it is comparatively faster than other ensemble classifiers.

## Core algorithm is parallelizable : 
Because the core XGBoost algorithm is parallelizable it can harness the power of multi-core computers. It is also parallelizable onto GPUâ€™s and across networks of computers making it feasible to train on very large datasets as well.

## Consistently outperforms other algorithm methods : 
It has shown better performance on a variety of machine learning benchmark datasets.

## Wide variety of tuning parameters : 
XGBoost internally has parameters for cross-validation, regularization, user-defined objective functions, missing values, tree parameters, scikit-learn compatible API etc.

## XGBoost (Extreme Gradient Boosting) belongs to a family of boosting algorithms and uses the gradient boosting (GBM) framework at its core. It is an optimized distributed gradient boosting library.
